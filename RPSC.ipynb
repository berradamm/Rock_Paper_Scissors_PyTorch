{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create custom dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 1\n",
    "\n",
    "# CUDA\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the image folder and the loaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we add all the transformation we want to apply to our images\n",
    "#Grayscale in order to make it faster (we dont take colors into account)\n",
    "#Flip and rotation in order data augmentation to our classifier \n",
    "transformations = transforms.Compose([transforms.Grayscale(),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomRotation(20, resample=Image.BILINEAR),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "image_data = datasets.ImageFolder('PPC2',transformations)\n",
    "\n",
    "### Split the data_set into a train and test dataset where 80% of the data as are used for training.\n",
    "train_size = int(0.8 * len(image_data))\n",
    "test_size = len(image_data) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(image_data, [train_size, test_size])\n",
    "\n",
    "#print (train_dataset)\n",
    "#print (train_size)\n",
    "#print (test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datas 4 by 4 \n",
    "dataloader_args = dict(shuffle=True, batch_size=4,num_workers=4, pin_memory=True)\n",
    "train_loader = dataloader.DataLoader(train_dataset, **dataloader_args)\n",
    "# Loading the test datas in one step \n",
    "dataloader_args = dict(shuffle=True, batch_size=len(test_dataset),num_workers=4, pin_memory=True)\n",
    "test_loader = dataloader.DataLoader(test_dataset, **dataloader_args)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two hidden Layers NN\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc0 = nn.Linear(32 * 32, 16*16) # Input layer (1024) , fc = fully connected layer \n",
    "        #self.fc1 = nn.Linear(1000, 3)\n",
    "        self.fc1 = nn.Linear(16 * 16, 8*8) # hidden Layer #1 (256)-> #hidden Layer #2 (64)\n",
    "        self.fc2 = nn.Linear(8*8, 3)# Output Layer (3)\n",
    "    def forward(self, x):\n",
    "        #out = self.drop_out(out)\n",
    "        x = x.view((-1, 1024))\n",
    "        h = F.selu(self.fc0(x))\n",
    "        h = F.selu(self.fc1(h))\n",
    "        out = self.fc2(h)\n",
    "        return F.log_softmax(out)    \n",
    "    \n",
    "    \n",
    "model = Model()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 300\n",
    "losses = []\n",
    "\n",
    "\n",
    "# iterate on the the test loader in order to get the Tensor needed to evaluate our trained model\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "#model.eval()\n",
    "#print (images.shape)\n",
    "#output = model(images)\n",
    "    \n",
    "train_size = len(train_loader.dataset)\n",
    "batch_size = (train_size / 4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Train & Test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Get Samples\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "\n",
    "        \n",
    "        # Init\n",
    "        optimizer.zero_grad()\n",
    "        # Predict\n",
    "        y_pred = model(data) \n",
    "\n",
    "         \n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(y_pred, target)\n",
    "        losses.append(loss.cpu().item())\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        # Display\n",
    "        if batch_idx % 4 == 1:\n",
    "            print('\\r Train Epoch: {}/{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch+1,\n",
    "                EPOCHS,\n",
    "                batch_idx * len(data), \n",
    "                train_size,\n",
    "                100. * batch_idx / batch_size, \n",
    "                loss.cpu().item()), \n",
    "                end='')\n",
    "            \n",
    "    # display final evaluation for this epoch\n",
    "    model.eval()\n",
    "    output = model(images)\n",
    "    pred = output.data.max(1)[1]\n",
    "    d = pred.eq(labels.data).cpu()\n",
    "    accuracy = d.sum().item()/d.size()[0]\n",
    "    \n",
    "    print('\\r Train Epoch: {}/{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Test Accuracy: {:.4f}%'.format(\n",
    "        epoch+1,\n",
    "        EPOCHS,\n",
    "        train_size, \n",
    "        train_size,\n",
    "        100. * batch_idx / batch_size, \n",
    "        loss.cpu().item(),\n",
    "        accuracy*100,\n",
    "        end=''))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
